#!/usr/bin/env python
# Adapted from the GDC help page 

from sys import argv, exit
import os

website = "https://docs.gdc.cancer.gov/API/Users_Guide/Appendix_A_Available_Fields/"
script_name = os.path.basename(argv.pop(0))

help_message = '''

Example:
        {script} cases.project.project_id=TCGA-BRCA data_category=Clinical
        
For more fields, visit:
        {site}

Or run: 
        {script} -p
        
        '''.format(site=website, script=script_name)

# Fieldname=Values (if more than one, comma separate)
if not argv or argv[0] in ['-h', '--help']:
    print(help_message)
    exit(0)

import requests
import json
import re
import tarfile
import glob
from lxml import html
from shutil import rmtree
import gzip

# Scrape then print "Available Fields" from GDC website
if argv[0] in ['-p', '--print']:
    page = requests.get(website)
    tree = html.fromstring(page.content)
    fields = tree.xpath('//td/text()')  # Field values are contained within <td> elements
    for field in fields:
        # Some of the capitalized values at the bottom ('GDC Conventions Supplemental') don't appear to be valid fields 
        if field.islower():
            print(field)         
    exit(0)

# Initialize filter dictionary for request
filters = {
    "op": "and",
    "content": []
}

# Add command line field->value pairs to filters dict
while len(argv) > 0:
    field, values = argv.pop().split('=')
    print(field, values)
    if ',' in values:
        values = values.split(',')
    else:
        values = [values]
    new_field = {
        "op": "in",
        "content": {"field":field, "value":values}
    }
    filters['content'].append(new_field)

# TODO: Save response as metadata
# List of fields to be returned by response
fields = [
    "file_name",
    "id",
    "cases.submitter_id",
    "cases.samples.sample_type",
    "cases.disease_type",
    "cases.project.project_id"
  ]

fields = ",".join(fields)

files_endpt = "https://api.gdc.cancer.gov/files"


# A POST is used, so the filter parameters can be passed directly as a Dict object.
params = {
    "filters": filters,
    "fields": fields,
    "format": "TSV",
    "size": 5    # Maximum number of records to return. TODO: Increase when done testing
    }

# The parameters are passed to 'json'
response = requests.post(files_endpt, headers = {"Content-Type": "application/json"}, json = params)
content = response.content.decode("utf-8").splitlines()

# Download files using ids contained in content
header = content.pop(0).split()
id_col = header.index('id')  # Get "id" column number
ids = [i.split('\t')[id_col] for i in content]  

data_endpt = "https://api.gdc.cancer.gov/data"
params = {"ids": ids}

response = requests.post(data_endpt,
                        data = json.dumps(params),
                        headers={
                            "Content-Type": "application/json"
                            })

# Get name of tar
response_head_cd = response.headers["Content-Disposition"]  
tar_file_name = re.findall("filename=(.+)", response_head_cd)[0]

with open(tar_file_name, "wb") as output_file:
    output_file.write(response.content)

output_dir = tar_file_name.replace('.tar.gz','')
os.mkdir(output_dir)

tar = tarfile.open(tar_file_name)

tar.extractall(output_dir)

for i in glob.glob(output_dir+'/*/*'):
    print(os.path.dirname(i))
    
    os.rename(i, output_dir+'/'+i.split('/')[-1])
    os.rmdir(os.path.dirname(i))

for gz_file in glob.glob(output_dir + '/*gz'):
    with gzip.open(gz_file) as handle:
        file_content = handle.read()
        with open(gz_file.replace('.gz', ''), 'wb') as outfile:
            outfile.write(file_content)
    os.remove(gz_file)

